{\rtf1\ansi\ansicpg1252\cocoartf2638
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0\cname textColor;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs28 \cf2 JOB3()\
BEGIN\
\
lines = spark.sparkContext.textFile(input_filepath).cache()\
filtered_lines = lines.filter(word: ! word.startswith("Id") & ! word.endswith("Text"))\
more_than_4_product_score = filtered_lines.filter(line: int(re.split(regex, line)[6]) >= 4)\
user_products = more_than_4_product_score \\map(line: (re.split(regex, line)[2], re.split(regex, line)[1]))\
user_products_reduced = user_products.reduceByKey(a, b: a + " " + b)\
at_least_3_products = user_products_reduced.filter(line: len(line[1].split(" ")) >= 3).\\ map(f=lambda x: (x[0], set(x[1].split(" "))))\
user_product_dictionary = at_least_3_products.collectAsMap()\
list_of_tuples = (tuple(i) for i in itertools.product(tuple(user_2_product_dictionary.keys()), repeat=2)\
\
                  if \
                  tuple(reversed(i)) >= tuple(i) & i[0] != i[1]\
\
                  & len(user_product_dictionary[i[0]].intersection(user_product_dictionary[i[1]])) >= 3)\
\
\
sorted_final = parallelize(sorted(list_of_tuples, x: x)).\\\
\
    map( x: (x, user_product_dictionary[x[0]].intersection(user_product_dictionary[x[1]]))).\\\
\
    filter(f=lambda x: len(x[1]) >= 3)\
collapsed_RDD = sorted_final.coalesce(1)\
saveAsTextFile(collapsed)\
\
END\
}