{\rtf1\ansi\ansicpg1252\cocoartf2638
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0\cname textColor;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs28 \cf2 JOB2()\
\
BEGIN\
\
lines = spark.sparkContext.textFile(input_filepath).cache()\
filtered_lines = lines.filter(word: ! word.startswith("Id") & ! word.endswith("Text"))\
user_product= filtered_lines.map(line: (re.split[(regex, line)[2], re.split(regex, line)[1], re.split(regex, line)[6]])\
user_product_reduced = user_product.reduceByKey(a, b: a + b)\
user_products = user_product_reduced.map(item: (item[0], item[1])). map(item: (item[0], [(x.[0], x.[1]) for x in item[1]]))\
ordered_RDD = user_2_products_RDD.map(f=lambda x: (x[0], sorted(x[1], key=lambda item: item[1], reverse=True)))\
top_five = ordered.map(item: (item[0], item[1 .. 5])).coalesce(1)\
to_order = top_five.collect()\
final = (sorted(to_order, x: x[0])).coalesce(1)\
saveAsTextFile(final)\
\
END\
}