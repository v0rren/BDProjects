{\rtf1\ansi\ansicpg1252\cocoartf2638
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red98\green105\blue113;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0\cname textColor;\cssrgb\c45882\c48627\c51765;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs28 \cf2 JOB1()\
\
BEGIN\
\
lines = spark.sparkContext.textFile(input_filepath).cache()\
filtered_lines = lines.filter(word: ! word.startswith("Id") & ! word.endswith("Text")) \cf3 //remove header\cf2 \
stripped_lines = filtered_lines.map(strip())\
years_text = stripped_lines.map( line: (datetime.fromtimestamp(int(re.split(regex, line)))\
years_text_reduced = years_text.reduceByKey(a, b: a + " " + b)\
years_word = years_text_reduced.map((item[0], findall('[^,;\\s]+', item[1])))\
years_most_used_words = years_word.map( mostcommon(item[0], Counter(item[1])\
years_top_10_most_used_words = years_most_used_words.map(item(item[0], item[1..10]))\
saveAsTextField(years_top_10_most_used_words)\
\
END\
\
}